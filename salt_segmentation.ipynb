{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook was used in the Kaggle competition \"tgs-salt-identification-challenge\" for image segmentation\n",
    "## The model takes a 101x101(x1 = grayscale) image + 1 feature and outputs an 101x101 image binary mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "#from itertools import chain\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_dir = 'train/images/'\n",
    "train_mask_dir = 'train/masks/'\n",
    "test_img_dir = 'test/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_names = [x.split('.')[0] for x in os.listdir(train_img_dir)]\n",
    "test_img_names = [x.split('.')[0] for x in os.listdir(test_img_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\", index_col=\"id\", usecols=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "print(\"Number of training samples:\" , len( train_df) ,\"\\n\", \"Number of test samples:\" , len(test_df) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"images\"] = [np.array(load_img(\"train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in train_img_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"masks\"] = [np.array(load_img(\"train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in train_img_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#is the mask empyty? i.e. is there any salt at all?\n",
    "saltarray = []\n",
    "for index, row in train_df.masks.iteritems():\n",
    "    saltarray.append(1 if row.any() else 0)\n",
    "train_df[\"salt\"]= saltarray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introduced it to test other image sizes\n",
    "# this can be useful when one is going to use a model with pre-trained weights, which requires a certain size\n",
    "img_size_ori = 101\n",
    "img_size_target = 101\n",
    "\n",
    "def upsample(img):# not used\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    \n",
    "def downsample(img):# not used\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid, depth_train, depth_valid, salt_train, salt_valid = train_test_split(\n",
    "    np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1),\n",
    "    np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1),\n",
    "    train_df.z.values,\n",
    "    train_df.salt.values,\n",
    "    test_size=0.1, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize depths\n",
    "depth_train_mean = depth_train.mean(axis=0, keepdims=True)\n",
    "depth_train_std = depth_train.std(axis=0, keepdims=True)\n",
    "\n",
    "depth_train = depth_train.astype(\"float64\")\n",
    "depth_train -= depth_train_mean\n",
    "depth_train /= depth_train_std\n",
    "\n",
    "depth_valid = depth_valid.astype(\"float64\")\n",
    "depth_valid -= depth_train_mean\n",
    "depth_valid /= depth_train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmenting the data\n",
    "# Typically a dataset of pics can be extended by symmetry operations, such as mirroring, rotation, adding noise, etc. \n",
    "# here is choose just all possibilities to mirror the images\n",
    "# so in total the train a validation data will be enlarged by a factor 4\n",
    "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "x_train = np.append(x_train, [np.flipud(x) for x in x_train], axis=0)\n",
    "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n",
    "y_train = np.append(y_train, [np.flipud(x) for x in y_train], axis=0)\n",
    "x_valid = np.append(x_valid, [np.fliplr(x) for x in x_valid], axis=0)\n",
    "x_valid = np.append(x_valid, [np.flipud(x) for x in x_valid], axis=0)\n",
    "y_valid = np.append(y_valid, [np.fliplr(x) for x in y_valid], axis=0)\n",
    "y_valid = np.append(y_valid, [np.flipud(x) for x in y_valid], axis=0)\n",
    "depth_train = np.append(depth_train, depth_train, axis=0)\n",
    "depth_train = np.append(depth_train, depth_train, axis=0)\n",
    "depth_valid = np.append(depth_valid, depth_valid, axis=0)\n",
    "depth_valid = np.append(depth_valid, depth_valid, axis=0)\n",
    "salt_train = np.append(salt_train, salt_train, axis=0)\n",
    "salt_train = np.append(salt_train, salt_train, axis=0)\n",
    "salt_valid = np.append(salt_valid, salt_valid, axis=0)\n",
    "salt_valid = np.append(salt_valid, salt_valid, axis=0)\n",
    "##maybe I should also try things like rot90, or scaling\n",
    "##does not use to much...\n",
    "print(x_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let me define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model, save_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add, ZeroPadding2D\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape, Flatten, Dense\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img#,save_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BatchActivate(x):\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    if activation == True:\n",
    "        x = BatchActivate(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(blockInput, num_filters=16, batch_activate = False):\n",
    "    x = BatchActivate(blockInput)\n",
    "    x = convolution_block(x, num_filters, (3,3) )\n",
    "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
    "    x = Add()([x, blockInput])\n",
    "    if batch_activate:\n",
    "        x = BatchActivate(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The metric for the competition was Intersection over Union (IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B):\n",
    "    batch_size = A.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch]>0, B[batch]>0\n",
    "#         if np.count_nonzero(t) == 0 and np.count_nonzero(p) > 0:\n",
    "#             metric.append(0)\n",
    "#             continue\n",
    "#         if np.count_nonzero(t) >= 1 and np.count_nonzero(p) == 0:\n",
    "#             metric.append(0)\n",
    "#             continue\n",
    "#         if np.count_nonzero(t) == 0 and np.count_nonzero(p) == 0:\n",
    "#             metric.append(1)\n",
    "#             continue\n",
    "        \n",
    "        intersection = np.logical_and(t, p)\n",
    "        union = np.logical_or(t, p)\n",
    "        iou = (np.sum(intersection > 0) + 1e-10 )/ (np.sum(union > 0) + 1e-10)\n",
    "        thresholds = np.arange(0.5, 1, 0.05)\n",
    "        s = []\n",
    "        for thresh in thresholds:\n",
    "            s.append(iou > thresh)\n",
    "        metric.append(np.mean(s))\n",
    "\n",
    "    return np.mean(metric)\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a U-Net model: a encoder + decoder architecture, see https://arxiv.org/abs/1505.04597\n",
    "# I will input the additional feature (=depth) in the middle layer via concatenation\n",
    "\n",
    "start_neurons = 32\n",
    "DropoutRatio = 0.5\n",
    "input_img = Input((101,101,1), name='img')\n",
    "input_features = Input((1, ), name='feat')\n",
    "\n",
    "conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_img)\n",
    "conv1 = residual_block(conv1,start_neurons * 1)\n",
    "conv1 = residual_block(conv1,start_neurons * 1, True)\n",
    "pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "pool1 = Dropout(DropoutRatio/2)(pool1)\n",
    "\n",
    "# 50 -> 25\n",
    "conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
    "conv2 = residual_block(conv2,start_neurons * 2)\n",
    "conv2 = residual_block(conv2,start_neurons * 2, True)\n",
    "pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "pool2 = Dropout(DropoutRatio)(pool2)\n",
    "\n",
    "# 25 -> 12\n",
    "\n",
    "conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
    "conv3 = residual_block(conv3,start_neurons * 4)\n",
    "conv3 = residual_block(conv3,start_neurons * 4, True)\n",
    "pool3 = MaxPooling2D((2, 2))(conv3)    \n",
    "pool3 = Dropout(DropoutRatio)(pool3)\n",
    "\n",
    "# 12 -> 6\n",
    "\n",
    "conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
    "\n",
    "conv4 = residual_block(conv4,start_neurons * 8)\n",
    "\n",
    "conv4 = residual_block(conv4,start_neurons * 8, True)\n",
    "\n",
    "pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "\n",
    "pool4 = Dropout(DropoutRatio)(pool4)\n",
    "\n",
    "#add depth\n",
    "\n",
    "f_repeat = RepeatVector(6*6)(input_features)\n",
    "f_conv = Reshape((6, 6, 1))(f_repeat)\n",
    "pool4_feat = concatenate([pool4, f_conv], -1)\n",
    "\n",
    "# Middle\n",
    "\n",
    "convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4_feat)\n",
    "\n",
    "convm = residual_block(convm,start_neurons * 16)\n",
    "\n",
    "convm = residual_block(convm,start_neurons * 16, True)\n",
    "    \n",
    "\n",
    "    # 6 -> 12\n",
    "deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "\n",
    "uconv4 = concatenate([deconv4, conv4])\n",
    "\n",
    "uconv4 = Dropout(DropoutRatio)(uconv4)\n",
    "    \n",
    "uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
    "\n",
    "uconv4 = residual_block(uconv4,start_neurons * 8)\n",
    "\n",
    "uconv4 = residual_block(uconv4,start_neurons * 8, True)\n",
    "    \n",
    "    # 12 -> 25\n",
    "#deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "\n",
    "deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n",
    "\n",
    "uconv3 = concatenate([deconv3, conv3])    \n",
    "\n",
    "uconv3 = Dropout(DropoutRatio)(uconv3)\n",
    "    \n",
    "uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
    "\n",
    "uconv3 = residual_block(uconv3,start_neurons * 4)\n",
    "\n",
    "uconv3 = residual_block(uconv3,start_neurons * 4, True)\n",
    "\n",
    "    # 25 -> 50\n",
    "deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "\n",
    "uconv2 = concatenate([deconv2, conv2])\n",
    "        \n",
    "uconv2 = Dropout(DropoutRatio)(uconv2)\n",
    "\n",
    "uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
    "\n",
    "uconv2 = residual_block(uconv2,start_neurons * 2)\n",
    "\n",
    "uconv2 = residual_block(uconv2,start_neurons * 2, True)\n",
    "    \n",
    "    # 50 -> 101\n",
    "    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "\n",
    "deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n",
    "\n",
    "uconv1 = concatenate([deconv1, conv1])\n",
    "    \n",
    "uconv1 = Dropout(DropoutRatio)(uconv1)\n",
    "\n",
    "uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
    "\n",
    "uconv1 = residual_block(uconv1,start_neurons * 1)\n",
    "\n",
    "uconv1 = residual_block(uconv1,start_neurons * 1, True)\n",
    "    \n",
    "#uconv1 = Dropout(DropoutRatio/2)(uconv1)\n",
    "#output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "\n",
    "output_layer_noActi = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv1)\n",
    "\n",
    "output_layer =  Activation('sigmoid')(output_layer_noActi)\n",
    "\n",
    "\n",
    "model = Model(inputs=[input_img, input_features], outputs=[output_layer])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=[my_iou_metric]) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "early_stopping = EarlyStopping(monitor='my_iou_metric', mode = 'max',patience=20, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(\"./unet_best.model\",monitor='my_iou_metric', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='my_iou_metric', mode = 'max', factor=0.5, patience=5, min_lr=0.0001, verbose=1)\n",
    "#reduce_lr = ReduceLROnPlateau(factor=0.2, patience=5, min_lr=0.00001, verbose=1)\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "history = model.fit({\"img\":np.concatenate((x_train,y_train)), \n",
    "                     \"feat\":np.concatenate((depth_train,depth_valid))},  \n",
    "                    np.concatenate((y_train,y_valid)),\n",
    "                    #validation_data=({'img': x_valid, 'feat': depth_valid}, y_valid), \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[early_stopping, model_checkpoint, reduce_lr], \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let me have a look at the loss and metric during training\n",
    "fig, (ax_loss, ax_score) = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax_loss.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "ax_loss.plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "ax_loss.legend()\n",
    "ax_score.plot(history.epoch, history.history[\"my_iou_metric\"], label=\"Train score\")\n",
    "ax_score.plot(history.epoch, history.history[\"val_my_iou_metric\"], label=\"Validation score\")\n",
    "ax_score.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model and find optimal threshold for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"unet_best.model\", custom_objects={\"my_iou_metric\":my_iou_metric} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reflection seems to help quite a bit, but not too much -> almost no difference whether you \n",
    "# flip just \"lr\" or in addition also \"ud\"...  \n",
    "def predict_result(model,test_data,img_size_target): # predict both orginal and reflect x\n",
    "    x_test = test_data[\"img\"]\n",
    "    preds_test = model.predict(test_data).reshape(-1, img_size_target, img_size_target)\n",
    "    x_test_reflect =  np.array([np.fliplr(x) for x in x_test])\n",
    "    preds_test_reflect = model.predict({\"img\": x_test_reflect,\"feat\": test_data[\"feat\"]}).reshape(-1, img_size_target, img_size_target)\n",
    "    #x_test_reflect2 =  np.array([np.flipud(x) for x in x_test])\n",
    "    #preds_test_reflect2 = model.predict({\"img\": x_test_reflect2,\"feat\": test_data[\"feat\"]}).reshape(-1, img_size_target, img_size_target)\n",
    "    #x_test_reflect3 =  np.array([np.flipud(x) for x in x_test_reflect])\n",
    "    #preds_test_reflect3 = model.predict({\"img\": x_test_reflect3,\"feat\": test_data[\"feat\"]}).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test += np.array([ np.fliplr(x) for x in preds_test_reflect] )\n",
    "    #preds_test += np.array([ np.flipud(x) for x in preds_test_reflect2] )\n",
    "    #preds_test += np.array([ np.fliplr(np.flipud(x)) for x in preds_test_reflect3] )\n",
    "    return preds_test/2 #4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let me now work on the optimal threshold. Many other competitors do the threshold optimization on the validation data. Let me try this as well and compare with a more fancy idea: a dynamical threshold, see later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score the model and do a threshold optimization by the best IoU.\n",
    "\n",
    "# taken from src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "\n",
    "\n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    #  if all zeros, original code  generate wrong  bins [-0.5 0 0.5],\n",
    "    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n",
    "#     temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))\n",
    "    #print(temp1)\n",
    "    intersection = temp1[0]\n",
    "    #print(\"temp2 = \",temp1[1])\n",
    "    #print(intersection.shape)\n",
    "   # print(intersection)\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    #print(np.histogram(labels, bins = true_objects))\n",
    "    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n",
    "    #print(\"area_true = \",area_true)\n",
    "    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "  \n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    intersection[intersection == 0] = 1e-9\n",
    "    \n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_valid = predict_result(model,{\"img\":x_valid,\"feat\":depth_valid},img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scoring for last model, choose threshold by validation data \n",
    "thresholds = np.linspace(0.2, 0.8, 30)\n",
    "\n",
    "ious = np.array([iou_metric_batch(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "print(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of using default 0.5 as threshold, use validation data to find the bewith a small bottleneckst threshold.\n",
    "threshold_best_index = np.argmax(ious) \n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "\n",
    "plt.plot(thresholds, ious)\n",
    "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternatively I want to try something else: Let me introduce a threshold that reflects the probabilty that there is salt in the image at all. Thus I build a second model - a binary classifier - that predicts whether there is salt in the image at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let me write a binary classifier that decides wheter there is salt or not in the image\n",
    "\n",
    "\n",
    "def SaltModel(input_shape):\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding: pads the border of X_input with zeroes\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X) #really this axis??\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # MORE CONVS\n",
    "    X = MaxPooling2D((2, 2))(X)\n",
    "    #shortcut = X\n",
    "    X = Conv2D(32, (3, 3), strides = (1, 1), padding=\"same\")(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(32, (3, 3), strides = (1, 1), padding=\"same\")(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    #X = layers.add([X, shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
    "\n",
    "    # FLATTEN X + FULLYCONNECTED\n",
    "    X = Flatten()(X)\n",
    "    \n",
    "    # MORE DENSE\n",
    "    X = Dense(128)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saltmodel = SaltModel((101,101,1))\n",
    "saltmodel.compile( optimizer = \"Adam\", loss='binary_crossentropy', metrics = [\"accuracy\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = saltmodel.fit(x = x_train, \n",
    "                        y = salt_train,\n",
    "                        validation_data=(x_valid, salt_valid),\n",
    "                        epochs=10,\n",
    "                        batch_size= 64,\n",
    "                        verbose =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first see how this performs on the validation data\n",
    "salt_threshold_valid = saltmodel.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric=[]\n",
    "for batch in range(800):\n",
    "        value = iou_metric(y_valid[batch],preds_valid[batch] > 0.5-0.2*(salt_threshold_valid[batch]) )\n",
    "        metric.append(value)\n",
    "np.mean(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now comes the test data for the competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array([(np.array(load_img(\"test/images/{}.png\".format(idx), grayscale = True))) / 255 for idx in test_img_names]).reshape(-1, img_size_target, img_size_target, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_test = depths_df[depths_df.index.isin(test_df.index)].z.values\n",
    "depth_test = depth_test.astype(\"float64\")\n",
    "depth_test -= depth_train_mean\n",
    "depth_test /= depth_train_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_threshold_test = saltmodel.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = predict_result(model,{'img': x_test, 'feat': depth_test},img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "used for converting the decoded image to rle mask\n",
    "as required for competition submission\n",
    "\"\"\"\n",
    "def rle_encode(im):\n",
    "    '''\n",
    "    im: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = im.flatten(order = 'F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try for both thresholds: the dynamic one seems to perform a little bit better, but almost no difference\n",
    "#pred_dict = {idx: rle_encode(np.round(downsample(preds_test[i]) > threshold_best )) for i, idx in enumerate(test_img_names) }\n",
    "pred_dict = {idx: rle_encode(np.round(downsample(preds_test[i]) > (0.5-0.2*(salt_threshold_test[i]-0.5)) ) ) for i, idx in enumerate(test_img_names)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the submission file & submit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c tgs-salt-identification-challenge -f \"./submission.csv\" -m \"unet with depth in middle layer, dyn. threshold opt., augmentation + avg in test set\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let me redo the same for a different loss function -- so-called lovasz-loss -- that is used by most of the other competitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code download from: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this loss only works in range (-∞，+∞), so adjust the threshold in the metric\n",
    "def my_iou_metric2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0], tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove last activation layer and use losvasz loss\n",
    "input_x = model.layers[0].input\n",
    "input_xx = model.layers[77].input\n",
    "\n",
    "output_layer = model.layers[-1].input\n",
    "modelCONT = Model(inputs=[input_x, input_xx], outputs=[output_layer])\n",
    "c = optimizers.adam(lr = 0.01)\n",
    "\n",
    "# lovasz_loss need input range (-∞，+∞), so cancel the last \"sigmoid\" activation  \n",
    "# Then the default threshod for pixel prediction is 0 instead of 0.5, as in my_iou_metric_2.\n",
    "modelCONT.compile(loss=lovasz_loss, optimizer=c, metrics=[my_iou_metric_2])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## takes very long to train, forget this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_my_iou_metric_2', mode = 'max',patience=20, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(\"./unet_bestCONT.model\",monitor='val_my_iou_metric_2', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric_2', mode = 'max',factor=0.5, patience=5, min_lr=0.0001, verbose=1)\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "history = modelCONT.fit({'img': x_train, 'feat': depth_train}, \n",
    "                    y_train,\n",
    "                    validation_data=({'img': x_valid, 'feat': depth_valid}, y_valid), \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[early_stopping, model_checkpoint, reduce_lr], \n",
    "                    verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
